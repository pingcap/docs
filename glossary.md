---
title: Glossary
summary: ACIDは、トランザクションの4つの主要なプロパティを指します。これらのプロパティには、原子性、一貫性、分離性、耐久性が含まれます。また、テーブルのバッチ作成やベースラインのキャプチャなど、TiDBの機能についても説明されています。さらに、インデックスのマージや継続的なプロファイリングなどの新機能も紹介されています。また、Raft EngineやTTLなどの用語も説明されています。
---

# 用語集 {#glossary}

## あ {#a}

### ACID {#acid}

ACID は、トランザクションの 4 つの主要なプロパティ (アトミック性、一貫性、分離性、耐久性) を指します。これらの各プロパティについては以下で説明します。

-   **原子性とは、**操作のすべての変更が実行されるか、まったく実行されないかのいずれかを意味します。 TiDB は、主キーを格納する[リージョン](#regionpeerraft-group)のアトミック性を保証し、トランザクションのアトミック性を実現します。

-   **一貫性とは**、トランザクションが常にデータベースをある一貫した状態から別の一貫した状態に移行させることを意味します。 TiDB では、データをメモリに書き込む前にデータの整合性が確保されます。

-   **分離とは、**処理中のトランザクションが完了するまで他のトランザクションから見えないことを意味します。これにより、整合性を犠牲にすることなく、同時トランザクションでデータの読み取りと書き込みが可能になります。 TiDB は現在、分離レベル`REPEATABLE READ`をサポートしています。

-   **耐久性と**は、トランザクションが一度コミットされると、システム障害が発生した場合でもコミットされたままになることを意味します。 TiKV は耐久性を確保するために永続storageを使用します。

## B {#b}

### テーブルのバッチ作成 {#batch-create-table}

テーブルのバッチ作成は、TiDB v6.0.0 で導入された機能です。この機能はデフォルトで有効になっています。 BR (バックアップ &amp; リストア) を使用して多数のテーブル (約 50,000) を含むデータをリストアする場合、この機能によりテーブルをバッチで作成することでリストア プロセスが大幅に高速化されます。詳細は[テーブルのバッチ作成](/br/br-batch-create-table.md)を参照してください。

### ベースラインのキャプチャ {#baseline-capturing}

ベースライン キャプチャでは、キャプチャ条件を満たすクエリをキャプチャし、それらのバインディングを作成します。 [アップグレード中の実行計画の回帰を防止する](/sql-plan-management.md#prevent-regression-of-execution-plans-during-an-upgrade)に使用されます。

### バケツ {#bucket}

[リージョン](#regionpeerraft-group)は論理的にバケットと呼ばれるいくつかの小さな範囲に分割されます。 TiKV はバケットごとにクエリ統計を収集し、バケットのステータスを PD に報告します。詳細は[バケット設計ドキュメント](https://github.com/tikv/rfcs/blob/master/text/0082-dynamic-size-region.md#bucket)を参照してください。

## C {#c}

### キャッシュされたテーブル {#cached-table}

キャッシュされたテーブル機能を使用すると、TiDB はテーブル全体のデータを TiDBサーバーのメモリにロードし、TiDB は TiKV にアクセスせずにメモリからテーブル データを直接取得するため、読み取りパフォーマンスが向上します。

### パーティションを結合する {#coalesce-partition}

パーティションの結合は、ハッシュまたはキーパーティションテーブル内のパーティションの数を減らす方法です。詳細については、 [ハッシュとキーのパーティションを管理する](/partitioned-table.md#manage-hash-and-key-partitions)を参照してください。

### 継続的なプロファイリング {#continuous-profiling}

TiDB 5.3.0 で導入された継続的プロファイリングは、システム コール レベルでリソースのオーバーヘッドを観察する方法です。継続的プロファイリングのサポートにより、TiDB はデータベースのソース コードを直接調べるのと同じくらい明確なパフォーマンスの洞察を提供し、研究開発および運用保守担当者がフレーム グラフを使用してパフォーマンスの問題の根本原因を特定できるように支援します。詳細は[TiDB ダッシュボード インスタンス プロファイリング - 継続的プロファイリング](/dashboard/continuous-profiling.md)を参照してください。

## D {#d}

### 動的プルーニング {#dynamic-pruning}

動的プルーニングモードは、 TiDB がパーティション化されたテーブルにアクセスするモードの 1 つです。動的プルーニング モードでは、各オペレーターは複数のパーティションへの直接アクセスをサポートします。したがって、TiDB は Union を使用しなくなりました。 Union 操作を省略すると、実行効率が向上し、Union の同時実行の問題を回避できます。

## 私 {#i}

### インデックスのマージ {#index-merge}

インデックス マージは、テーブルにアクセスするために TiDB v4.0 で導入された方法です。この方法を使用すると、TiDB オプティマイザーはテーブルごとに複数のインデックスを使用し、各インデックスから返された結果をマージできます。一部のシナリオでは、この方法によりテーブル全体のスキャンが回避され、クエリがより効率的になります。 v5.4 以降、インデックス マージは GA 機能になりました。

### インメモリ悲観的ロック {#in-memory-pessimistic-lock}

インメモリ悲観的ロックは、TiDB v6.0.0 で導入された新機能です。この機能が有効になっている場合、悲観的ロックは通常、リージョンリーダーのメモリにのみ保存され、ディスクに保存されたり、 Raftを介して他のレプリカに複製されたりしません。この機能により、悲観的ロックを取得するオーバーヘッドが大幅に削減され、悲観的トランザクションのスループットが向上します。

## L {#l}

### リーダー/フォロワー/学習者 {#leader-follower-learner}

Leader/ Follower/ Learnerはそれぞれ[仲間](#regionpeerraft-group)のRaftグループ内の役割に対応します。リーダーはすべてのクライアント要求に対応し、データをフォロワーに複製します。グループ リーダーが失敗した場合、フォロワーの 1 人が新しいリーダーとして選出されます。学習者は、レプリカの追加のプロセスでのみ機能する非投票フォロワーです。

## M {#m}

### MPP {#mpp}

TiDB v5.0 以降、 TiFlashノードを介して大規模並列処理 (MPP)アーキテクチャが導入され、 TiFlashノード間で大規模な結合クエリの実行ワークロードが共有されます。 MPP モードが有効な場合、TiDB はコストに基づいて、MPP フレームワークを使用して計算を実行するかどうかを決定します。 MPP モードでは、計算中に結合キーが Exchange 操作を通じて再配布されるため、各TiFlashノードへの計算圧力が分散され、計算が高速化されます。詳細については、 [TiFlash MPP モードを使用する](/tiflash/use-tiflash-mpp-mode.md)を参照してください。

## ○ {#o}

### 古い値 {#old-value}

TiCDC によって出力される増分変更ログの「元の値」。 TiCDC によって出力される増分変更ログに「元の値」が含まれるかどうかを指定できます。

### オペレーター {#operator}

演算子は、スケジュールの目的でリージョンに適用されるアクションのコレクションです。オペレーターは、「リージョン2 のリーダーをストア 5 に移行」や「リージョン2 のレプリカをストア 1、4、5 に移行」などのスケジュール タスクを実行します。

演算子は[スケジューラ](#scheduler)によって計算および生成することも、外部 API によって作成することもできます。

### オペレータステップ {#operator-step}

オペレーター ステップは、オペレーターを実行するステップです。通常、オペレータには複数のオペレータ ステップが含まれます。

現在、PD によって生成される利用可能なステップには次のものがあります。

-   `TransferLeader` : 指定されたメンバーにリーダーシップを譲渡します
-   `AddPeer` : 指定されたストアにピアを追加します
-   `RemovePeer` :リージョンのピアを削除します
-   `AddLearner` : 指定されたストアに学習者を追加します
-   `PromoteLearner` : 指定された学習者を投票メンバーに昇格します
-   `SplitRegion` : 指定されたリージョンを2 つに分割します

## P {#p}

### パーティショニング {#partitioning}

[パーティショニング](/partitioned-table.md) 、テーブルをより小さなテーブル パーティションに物理的に分割することを指します。これは、RANGE、LIST、HASH、KEY パーティション化などのパーティション メソッドによって実行できます。

### 保留中/ダウン中 {#pending-down}

「保留中」と「ダウン」は、ピアの 2 つの特殊な状態です。 「保留中」は、フォロワーまたは学習者のRaftログがリーダーのログと大きく異なることを示します。保留中のフォロワーはリーダーとして選出できません。 「ダウン」とは、ピアが長期間にわたってリーダーに応答しなくなった状態を指します。通常、これは、対応するノードがダウンしているか、ネットワークから孤立していることを意味します。

### ポイントゲット {#point-get}

ポイント get は、一意のインデックスまたはプライマリ インデックスによって単一行のデータを読み取ることを意味し、返される結果セットは最大 1 行です。

### 述語列 {#predicate-columns}

ほとんどの場合、SQL ステートメントを実行するとき、オプティマイザーは一部の列 ( `WHERE` 、 `JOIN` 、 `ORDER BY` 、および`GROUP BY`ステートメントの列など) の統計のみを使用します。これらの使用される列は述語列と呼ばれます。詳細は[いくつかの列の統計を収集する](/statistics.md#collect-statistics-on-some-columns)を参照してください。

## Q {#q}

### クォータ制限 {#quota-limiter}

クォータ リミッターは、TiDB v6.0.0 で導入された実験的機能です。 TiKV がデプロイされているマシンのリソースが限られている場合 (たとえば、CPU が 4 v とメモリが 16 G しかない場合)、TiKV のフォアグラウンドがあまりにも多くの読み取りおよび書き込みリクエストを処理する場合、バックグラウンドで使用される CPU リソースは、そのような処理を支援するために占有されます。これは、TiKV のパフォーマンスの安定性に影響します。この状況を回避するには、 [クォータ関連の設定項目](/tikv-configuration-file.md#quota)設定して、フォアグラウンドで使用される CPU リソースを制限します。

## R {#r}

### Raft Engine {#raft-engine}

Raft Engine は、ログ構造設計を備えた組み込み永続storageエンジンです。 TiKV がマルチ Raft ログを保存できるように構築されています。 v5.4 以降、TiDB はログstorageエンジンとしてRaft Engineの使用をサポートしています。詳細は[Raft Engine](/tikv-configuration-file.md#raft-engine)を参照してください。

### リージョン/ピア/ Raftグループ {#region-peer-raft-group}

リージョンはTiKV の最小のデータstorageであり、それぞれがデータの範囲 (デフォルトでは 96 MiB) を表します。各リージョンにはデフォルトで 3 つのレプリカがあります。リージョンのレプリカはピアと呼ばれます。同じリージョンの複数のピアはRaftコンセンサス アルゴリズムを介してデータを複製するため、ピアはRaftインスタンスのメンバーでもあります。 TiKV は Multi-Raft を使用してデータを管理します。つまり、各リージョンには、対応する孤立したRaftグループが存在します。

### リージョン分割 {#region-split}

データ書き込みが増加すると領域が生成されます。分割のプロセスはリージョン分割と呼ばれます。

リージョン分割のメカニズムは、1 つの初期リージョンを使用してキー空間全体をカバーし、リージョンのサイズまたはキーの数がしきい値に達するたびに既存のリージョンを分割して新しいリージョンを生成することです。

### 復元する {#restore}

復元はバックアップ操作の逆です。これは、準備されたバックアップからデータを取得することによって、システムを以前の状態に戻すプロセスです。

## S {#s}

### スケジューラ {#scheduler}

スケジューラは、スケジューリング タスクを生成する PD のコンポーネントです。 PD の各スケジューラは独立して実行され、異なる目的を果たします。一般的に使用されるスケジューラは次のとおりです。

-   `balance-leader-scheduler` : リーダーの配置のバランスをとる
-   `balance-region-scheduler` : ピアの分散のバランスをとります。
-   `hot-region-scheduler` : ホット リージョンの分散のバランスをとります。
-   `evict-leader-{store-id}` : ノードのすべてのリーダーを削除します (ローリング アップグレードによく使用されます)

### 店 {#store}

ストアとは、TiKV クラスター内のstorageノード ( `tikv-server`のインスタンス) を指します。各ストアには、対応する TiKV インスタンスがあります。

## T {#t}

### Top SQL {#top-sql}

Top SQL は、指定された時間範囲内で TiDB または TiKV ノードの高負荷に寄与する SQL クエリを見つけるのに役立ちます。詳細は[Top SQLユーザー ドキュメント](/dashboard/top-sql.md)を参照してください。

### TSO {#tso}

TiKV は分散storageシステムであるため、単調増加するタイムスタンプを割り当てるには、グローバル タイミング サービスである Timestamp Oracle (TSO) が必要です。 TiKV では、このような機能は PD によって提供され、Google [スパナ](http://static.googleusercontent.com/media/research.google.com/en//archive/spanner-osdi2012.pdf)では、この機能は複数のアトミック時計と GPS によって提供されます。

### TTL {#ttl}

[生存時間 (TTL)](/time-to-live.md)は、TiDB データの有効期間を行レベルで管理できる機能です。 TTL 属性を持つテーブルの場合、TiDB はデータの有効期間を自動的にチェックし、期限切れのデータを行レベルで削除します。
