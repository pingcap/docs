---
title: Bookshop Example Application
---

# Bookshop Example Application

Bookshop is a virtual online bookstore application, you can easily buy books of various categories in Bookshop, and you can also rate on the books you have read.

## Import data

### Method 1: Through `tiup demo` command line

If you use [TiUP](/tiup/tiup-reference.md#tiup-reference) to deploy a TiDB cluster or you can directly connect to your TiDB server, you can quickly generate and import sample data for the Bookshop application with the following commands :

{{< copyable "shell" >}}

```shell
tiup demo bookshop prepare
```

This command will connect to the `4000` port on the `127.0.0.1` address by default, use the `root` user to log in with no password, and create a [table structure](#details-about-table) in a database named `bookshop` by default.

#### Configure connection information

You can modify the default connection information with the following parameters:

| Parameter    | Shorthand | Defaults      | Explain           |
| ------------ | ---- | ----------- | -------------- |
| `--host`     | `-H` | `127.0.0.1` | Database address     |
| `--port`     | `-P` | `4000`      | Database port     |
| `--user`     | `-U` | `root`      | Database user     |
| `--password` | `-p` | none        | Database user password |
| `--db`       | `-D` | `bookshop`  | Database name     |

For example, if you want to connect to a database on TiDB Cloud, you can specify the connection information to connect with the following command:

{{< copyable "shell" >}}

```shell
tiup demo bookshop prepare -U root -H tidb.xxx.yyy.ap-northeast-1.prod.aws.tidbcloud.com -P 4000 -p
```

#### Setting data volume

In addition, you can also specify the amount of data generated by each database table through the following parameters:

| Parameter        | Defaults   | Explain                              |
| ----------- | -------- | --------------------------------- |
| `--users`   | `10000`  | Specifies the number of rows of data to generate in the `users` table   |
| `--authors` | `20000`  | Specifies the number of rows to generate in the `authors` table |
| `--books`   | `20000`  | Specifies the number of rows of data to generate in the `books` table   |
| `--orders`  | `300000` | Specifies the number of rows of data to generate in the `orders` table  |
| `--ratings` | `300000` | Specifies the number of rows of data to generate in the `ratings` table |

For example, the following command specifies to generate 500,000 lines of basic book information via the `--books` parameter, 100,000 lines of author information via the `--authors` parameter, 1,000,000 lines of rating records via the `--ratings` parameter, and 1,000,000 lines of order records via the `--orders` parameter.

{{< copyable "shell" >}}

```shell
tiup demo bookshop prepare --users=200000 --books=500000 --authors=100000 --ratings=1000000 --orders=1000000 --drop-tables
```

You can delete the original table structure through the `--drop-tables` parameter. For more parameter descriptions, you can use the command `tiup demo bookshop --help` to understand.

### Method 2: Through the TiDB Cloud Import function

On the database details page of TiDB Cloud, you can click the **Import** button to enter the **Data Import Task** page. On this page, follow the steps below to import the Bookshop sample data from AWS S3 to your TiDB Cloud:

1. Copy the following **Bucket URL** and **Role-ARN** into the corresponding input boxes on the page:

   **Bucket URL**:

    {{< copyable "" >}}

    ```
    s3://developer.pingcap.com/bookshop/
    ```

   **Role-ARN**:

   {{< copyable "" >}}

   ```
   arn:aws:iam::494090988690:role/s3-tidb-cloud-developer-access
   ```

   In this example data, 200,000 user information, 500,000 book information, 100,000 author information, 1 million rating records, and 1 million order information are pre-generated.

2. Select **Bucket Region** as **US West (Oregon)**.
3. Select **Data Format** as **TiDB Dumpling**.

   ![Import Bookshop data in TiDB Cloud](/media/develop/tidb_cloud_import_bookshop_data.png)

4. Enter your database login information.
5. Click the **Import** button to confirm the import.
6. Wait for TiDB Cloud to complete the data import.

   ![Bookshop data importing](/media/develop/importing_bookshop_data.png)

   If the following error message appears during the import process, you need to use the `DROP TABLE bookshop;` command to clear the previously created sample database and then import it again.

   > table(s) [`bookshop`.`authors`, `bookshop`.`book_authors`, `bookshop`.`books`, `bookshop`.`orders`, `bookshop`.`ratings`, `bookshop`.`users`] are not empty.

You can get more information about TiDB Cloud through [TiDB Cloud Documentation](https://docs.pingcap.com/tidbcloud).

### View data import status

After the import is complete, you can access the data volume information of each table through the following SQL statement:

{{< copyable "sql" >}}

```sql
SELECT
    CONCAT(table_schema,'.',table_name) AS 'Table Name',
    table_rows AS 'Number of Rows',
    CONCAT(ROUND(data_length/(1024*1024*1024),4),'G') AS 'Data Size',
    CONCAT(ROUND(index_length/(1024*1024*1024),4),'G') AS 'Index Size',
    CONCAT(ROUND((data_length+index_length)/(1024*1024*1024),4),'G') AS 'Total'
FROM
    information_schema.TABLES
WHERE table_schema LIKE 'bookshop';
```

```
+-----------------------+----------------+-----------+------------+---------+
| Table Name            | Number of Rows | Data Size | Index Size | Total   |
+-----------------------+----------------+-----------+------------+---------+
| bookshop.orders       |        1000000 | 0.0373G   | 0.0075G    | 0.0447G |
| bookshop.book_authors |        1000000 | 0.0149G   | 0.0149G    | 0.0298G |
| bookshop.ratings      |        4000000 | 0.1192G   | 0.1192G    | 0.2384G |
| bookshop.authors      |         100000 | 0.0043G   | 0.0000G    | 0.0043G |
| bookshop.users        |         195348 | 0.0048G   | 0.0021G    | 0.0069G |
| bookshop.books        |        1000000 | 0.0546G   | 0.0000G    | 0.0546G |
+-----------------------+----------------+-----------+------------+---------+
6 rows in set (0.03 sec)
```

## Details about Table

The following describes the database table structure of the Bookshop application in detail:

### `books` table

This table is used to store the basic information of the book.

| Field name   | Type          | Explain                                                          |
|--------------|---------------|------------------------------------------------------------------|
| id           | bigint(20)    | Unique ID of the book                                            |
| title        | varchar(100)  | Book title                                                       |
| type         | enum          | Types of books (eg: magazines / animation / teaching aids, etc.) |
| stock        | bigint(20)    | Stock                                                            |
| price        | decimal(15,2) | Price                                                            |
| published_at | datetime      | Date of publish                                                  |

### `authors` table

This table is used to store the author's basic information.

| Field name | Type         | Explain                                               |
|------------|--------------|-------------------------------------------------------|
| id         | bigint(20)   | The unique ID of author                               |
| name       | varchar(100) | Name                                                  |
| gender     | tinyint(1)   | Biological gender (0: female, 1: male, NULL: unknown) |
| birth_year | smallint(6)  | The year of birth                                     |
| death_year | smallint(6)  | The year of death                                     |

### `users` table

This table is used to store the information of users who use the Bookshop application.

| Field name | Type          | Explain               |
|------------|---------------|-----------------------|
| id         | bigint(20)    | The unique ID of user |
| balance    | decimal(15,2) | Balance               |
| nickname   | varchar(100)  | Nickname              |

### `ratings` table

This table is used to store records of user ratings for books.

| Field name | Type     | Explain                                                    |
|------------|----------|------------------------------------------------------------|
| book_id    | bigint   | Unique ID of the book (linked to [books](#books-table))    |
| user_id    | bigint   | User's unique identifier (linked to [users](#users-table)) |
| score      | tinyint  | User rating (1-5)                                          |
| rated_at   | datetime | Rating time                                                |

### `book_authors` table

An author may write multiple books, and a book may require multiple authors to write at the same time. This table is used to store the correspondence between books and authors.

| Field name | Type       | Explain                                                      |
|------------|------------|--------------------------------------------------------------|
| book_id    | bigint(20) | Unique ID of the book (linked to [books](#books-table))      |
| author_id  | bigint(20) | Unique ID of the author（Link to [authors](#authors-table)） |

### `orders` table

This table is used to store order information for users to purchase books.

| Field name | Type       | Explain                                                        |
|------------|------------|----------------------------------------------------------------|
| id         | bigint(20) | The unique ID of the order                                     |
| book_id    | bigint(20) | Unique ID of the book (linked to [books](#books-table))        |
| user_id    | bigint(20) | User unique identifier (associated with [users](#users-table)) |
| quantity   | tinyint(4) | Purchase quantity                                              |
| ordered_at | datetime   | Purchase time                                                  |

## Database initialization script `dbinit.sql` 

{{< copyable "sql" >}}

```sql
CREATE DATABASE IF NOT EXISTS `bookshop`;

DROP TABLE IF EXISTS `bookshop`.`books`;
CREATE TABLE `bookshop`.`books` (
  `id` bigint(20) AUTO_RANDOM NOT NULL,
  `title` varchar(100) NOT NULL,
  `type` enum('Magazine', 'Novel', 'Life', 'Arts', 'Comics', 'Education & Reference', 'Humanities & Social Sciences', 'Science & Technology', 'Kids', 'Sports') NOT NULL,
  `published_at` datetime NOT NULL,
  `stock` int(11) DEFAULT '0',
  `price` decimal(15,2) DEFAULT '0.0',
  PRIMARY KEY (`id`) CLUSTERED
) DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin;

DROP TABLE IF EXISTS `bookshop`.`authors`;
CREATE TABLE `bookshop`.`authors` (
  `id` bigint(20) AUTO_RANDOM NOT NULL,
  `name` varchar(100) NOT NULL,
  `gender` tinyint(1) DEFAULT NULL,
  `birth_year` smallint(6) DEFAULT NULL,
  `death_year` smallint(6) DEFAULT NULL,
  PRIMARY KEY (`id`) CLUSTERED
) DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin;

DROP TABLE IF EXISTS `bookshop`.`book_authors`;
CREATE TABLE `bookshop`.`book_authors` (
  `book_id` bigint(20) NOT NULL,
  `author_id` bigint(20) NOT NULL,
  PRIMARY KEY (`book_id`,`author_id`) CLUSTERED
) DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin;

DROP TABLE IF EXISTS `bookshop`.`ratings`;
CREATE TABLE `bookshop`.`ratings` (
  `book_id` bigint NOT NULL,
  `user_id` bigint NOT NULL,
  `score` tinyint NOT NULL,
  `rated_at` datetime NOT NULL DEFAULT NOW() ON UPDATE NOW(),
  PRIMARY KEY (`book_id`,`user_id`) CLUSTERED,
  UNIQUE KEY `uniq_book_user_idx` (`book_id`,`user_id`)
) DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin;
ALTER TABLE `bookshop`.`rating` SET TIFLASH REPLICA 1;

DROP TABLE IF EXISTS `bookshop`.`users`;
CREATE TABLE `bookshop`.`users` (
  `id` bigint AUTO_RANDOM NOT NULL,
  `balance` decimal(15,2) DEFAULT '0.0',
  `nickname` varchar(100) UNIQUE NOT NULL,
  PRIMARY KEY (`id`)
) DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin;

DROP TABLE IF EXISTS `bookshop`.`orders`;
CREATE TABLE `bookshop`.`orders` (
  `id` bigint(20) AUTO_RANDOM NOT NULL,
  `book_id` bigint(20) NOT NULL,
  `user_id` bigint(20) NOT NULL,
  `quality` tinyint(4) NOT NULL,
  `ordered_at` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
  PRIMARY KEY (`id`) CLUSTERED,
  KEY `orders_book_id_idx` (`book_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin
```
