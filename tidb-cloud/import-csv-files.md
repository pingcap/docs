---
title: Import CSV Files from Amazon S3 or GCS into TiDB Cloud
summary: Learn how to import CSV files from Amazon S3 or GCS into TiDB Cloud.
---

# Amazon S3 または GCS からTiDB Cloudに CSV ファイルをインポート {#import-csv-files-from-amazon-s3-or-gcs-into-tidb-cloud}

このドキュメントでは、CSV ファイルを Amazon Simple Storage Service (Amazon S3) または Google Cloud Storage (GCS) からTiDB Cloudにインポートする方法について説明します。

> **注記：**
>
> -   データの一貫性を確保するために、 TiDB Cloud空のテーブルにのみ CSV ファイルをインポートできます。すでにデータが含まれている既存のテーブルにデータをインポートするには、このドキュメントに従ってTiDB Cloudを使用して一時的な空のテーブルにデータをインポートし、その後`INSERT SELECT`ステートメントを使用してデータをターゲットの既存のテーブルにコピーします。
> -   TiDB 専用クラスターにチェンジフィードがある場合、現在のデータインポート機能は[物理インポートモード](https://docs.pingcap.com/tidb/stable/tidb-lightning-physical-import-mode)を使用するため、データをクラスターにインポートできません ([**データのインポート]**ボタンが無効になります)。このモードでは、インポートされたデータは変更ログを生成しないため、変更フィードはインポートされたデータを検出できません。

## ステップ 1. CSV ファイルを準備する {#step-1-prepare-the-csv-files}

1.  CSV ファイルが 256 MB より大きい場合は、それぞれのサイズが 256 MB 程度の小さなファイルに分割することを検討してください。

    TiDB Cloudは非常に大きな CSV ファイルのインポートをサポートしていますが、サイズが約 256 MB の複数の入力ファイルで最高のパフォーマンスを発揮します。これは、 TiDB Cloud が複数のファイルを並行して処理できるため、インポート速度が大幅に向上する可能性があります。

2.  CSV ファイルに次の名前を付けます。

    -   CSV ファイルにテーブル全体のすべてのデータが含まれている場合は、ファイルに`${db_name}.${table_name}.csv`形式で名前を付けます。これは、データをインポートするときに`${db_name}.${table_name}`テーブルにマップされます。

    -   1 つのテーブルのデータが複数の CSV ファイルに分割されている場合は、これらの CSV ファイルに数字のサフィックスを追加します。たとえば、 `${db_name}.${table_name}.000001.csv`と`${db_name}.${table_name}.000002.csv`です。数値接尾辞は連続していなくてもかまいませんが、昇順である必要があります。また、すべての接尾辞が同じ長さになるように、数値の前にゼロを追加する必要があります。

    -   TiDB Cloud は、次の形式の圧縮ファイルのインポートをサポートしています: `.gzip` 、 `.gz` 、 `.zstd` 、 `.zst`および`.snappy` 。圧縮された CSV ファイルをインポートする場合は、ファイルに`${db_name}.${table_name}.${suffix}.csv.${compress}`形式で名前を付けます`${suffix}`はオプションで、「000001」などの任意の整数を指定できます。たとえば、 `trips.000001.csv.gz`ファイルを`bikeshare.trips`テーブルにインポートする場合は、ファイルの名前を`bikeshare.trips.000001.csv.gz`に変更する必要があります。

    > **注記：**
    >
    > -   圧縮する必要があるのはデータ ファイルだけであり、データベースやテーブル スキーマ ファイルは圧縮する必要はありません。
    > -   より良いパフォーマンスを実現するには、各圧縮ファイルのサイズを 100 MiB に制限することをお勧めします。
    > -   非圧縮ファイルの場合、場合によっては前述のルールに従って CSV ファイル名を更新できない場合 (たとえば、CSV ファイルのリンクが他のプログラムでも使用されている場合)、ファイル名を変更せずに、 [ステップ4](#step-4-import-csv-files-to-tidb-cloud)の**マッピング設定を**使用して、ソース データを単一のターゲット テーブルにインポートします。

## ステップ 2. ターゲットテーブルスキーマを作成する {#step-2-create-the-target-table-schemas}

CSV ファイルにはスキーマ情報が含まれていないため、CSV ファイルからTiDB Cloudにデータをインポートする前に、次のいずれかの方法を使用してテーブル スキーマを作成する必要があります。

-   方法 1: TiDB Cloudで、ソース データのターゲット データベースとテーブルを作成します。

-   方法 2: CSV ファイルが配置されている Amazon S3 または GCS ディレクトリに、次のようにソース データのターゲット テーブル スキーマ ファイルを作成します。

    1.  ソース データのデータベース スキーマ ファイルを作成します。

        CSV ファイルが[ステップ1](#step-1-prepare-the-csv-files)の命名規則に従っている場合、データベース スキーマ ファイルはデータ インポートのオプションになります。それ以外の場合、データベース スキーマ ファイルは必須です。

        各データベース スキーマ ファイルは`${db_name}-schema-create.sql`形式であり、 `CREATE DATABASE` DDL ステートメントが含まれている必要があります。データをインポートするときに、このファイルを使用して、 TiDB Cloud はデータを保存する`${db_name}`を作成します。

        たとえば、次のステートメントを含む`mydb-scehma-create.sql`ファイルを作成すると、データのインポート時にTiDB Cloud は`mydb`データベースを作成します。

        ```sql
        CREATE DATABASE mydb;
        ```

    2.  ソース データのテーブル スキーマ ファイルを作成します。

        CSV ファイルが配置されている Amazon S3 または GCS ディレクトリにテーブル スキーマ ファイルを含めない場合、データのインポート時にTiDB Cloudは対応するテーブルを作成しません。

        各テーブル スキーマ ファイルは`${db_name}.${table_name}-schema.sql`形式であり、 `CREATE TABLE` DDL ステートメントが含まれている必要があります。データをインポートすると、このファイルを使用して、 TiDB Cloud は`${db_name}`データベースに`${db_table}`テーブルを作成します。

        たとえば、次のステートメントを含む`mydb.mytable-schema.sql`ファイルを作成すると、データをインポートすると、 TiDB Cloud は`mydb`データベースに`mytable`テーブルを作成します。

        ```sql
        CREATE TABLE mytable (
        ID INT,
        REGION VARCHAR(20),
        COUNT INT );
        ```

        > **注記：**
        >
        > 各ファイルには`${db_name}.${table_name}-schema.sql`つの DDL ステートメントのみを含める必要があります。ファイルに複数の DDL ステートメントが含まれている場合、最初の DDL ステートメントのみが有効になります。

## ステップ 3. クロスアカウント アクセスを構成する {#step-3-configure-cross-account-access}

TiDB Cloud がAmazon S3 または GCS バケット内の CSV ファイルにアクセスできるようにするには、次のいずれかを実行します。

-   CSV ファイルが Amazon S3 にある場合、 [Amazon S3 アクセスを設定する](/tidb-cloud/config-s3-and-gcs-access.md#configure-amazon-s3-access) .

    AWS アクセス キーまたはロール ARN を使用してバケットにアクセスできます。完了したら、アクセス キー (アクセス キー ID とシークレット アクセス キーを含む) またはロール ARN 値をメモします ( [ステップ4](#step-4-import-csv-files-to-tidb-cloud)で必要になります)。

-   CSV ファイルが GCS にある場合は、 [GCS アクセスを構成する](/tidb-cloud/config-s3-and-gcs-access.md#configure-gcs-access) 。

## ステップ 4. CSV ファイルをTiDB Cloudにインポートする {#step-4-import-csv-files-to-tidb-cloud}

CSV ファイルをTiDB Cloudにインポートするには、次の手順を実行します。

1.  ターゲットクラスターの**インポート**ページを開きます。

    1.  [TiDB Cloudコンソール](https://tidbcloud.com/)にログインし、プロジェクトの[**クラスター**](https://tidbcloud.com/console/clusters)ページに移動します。

        > **ヒント：**
        >
        > 複数のプロジェクトがある場合は、<mdsvgicon name="icon-left-projects">左下隅の をクリックして、別のプロジェクトに切り替えます。</mdsvgicon>

    2.  ターゲット クラスターの名前をクリックして概要ページに移動し、左側のナビゲーション ペインで**[インポート]**をクリックします。

2.  **インポート**ページで:
    -   TiDB 専用クラスターの場合は、右上隅にある**「データのインポート」**をクリックします。
    -   TiDB サーバーレス クラスターの場合は、アップロード領域の上にある**[S3 からデータをインポート]**リンクをクリックします。

3.  ソース CSV ファイルに次の情報を指定します。

    -   **場所**: **Amazon S3**を選択します。

    -   **データ形式**: **CSV**を選択します。 CSV 構成を編集する必要がある場合は、 **「CSV 構成の編集」**をクリックして CSV 固有の構成を更新します。詳細については、 [データをインポートするための CSV 構成](/tidb-cloud/csv-config-for-import-data.md)を参照してください。

        > **注記：**
        >
        > 区切り文字と区切り文字の設定には、英数字と特定の特殊文字の両方を使用できます。サポートされている特殊文字には、 `\t` 、 `\b` 、 `\n` 、 `\r` 、 `\f` 、および`\u0001`が含まれます。

    -   **バケット URI** : CSV ファイルが配置されているバケット URI を選択します。 URI の末尾に`/`含める必要があることに注意してください (例: `s3://sampledate/ingest/` )。

    -   **バケット アクセス**(このフィールドは AWS S3 でのみ表示されます): AWS アクセス キーまたは AWS ロール ARN を使用してバケットにアクセスできます。詳細については、 [Amazon S3 アクセスを構成する](/tidb-cloud/config-s3-and-gcs-access.md#configure-amazon-s3-access)を参照してください。
        -   **AWS アクセス キー**: AWS アクセス キー ID と AWS シークレット アクセス キーを入力します。
        -   **AWS ロール ARN** : AWS ロール ARN 値を入力します。

4.  **事前に作成されたテーブルにインポートする**か、 **S3 からスキーマとデータをインポートするか**を選択できます。

    -   **事前に作成されたテーブルにインポートを使用**すると、事前に TiDB にテーブルを作成し、データをインポートするテーブルを選択できます。この場合、インポートするテーブルを最大 1000 個選択できます。テーブルを作成するには、左側のナビゲーション ペインで**[Chat2Qury]**をクリックします。 Chat2Qury の使用方法の詳細については、 [AI を活用した Chat2Query でデータを探索する](/tidb-cloud/explore-data-with-chat2query.md)を参照してください。
    -   **S3 からスキーマとデータをインポートすると、**テーブルを作成する SQL スクリプトと、S3 に保存されている対応するデータを TiDB に直接インポートできます。

5.  ソース ファイルが命名規則を満たしていない場合は、各ターゲット テーブルとそれに対応する CSV ファイルに対してカスタム マッピング ルールを定義できます。その後、提供されたカスタム マッピング ルールを使用してデータ ソース ファイルが再スキャンされます。マッピングを変更するには、 **「詳細設定」**に移動し、 **「マッピング設定」**をクリックします。 **[マッピング設定] は、** **[事前作成されたテーブルにインポート] を**選択した場合にのみ使用できることに注意してください。

    -   **ターゲット データベース**: 選択したターゲット データベースの名前を入力します。

    -   **ターゲット テーブル**: 選択したターゲット テーブルの名前を入力します。このフィールドは 1 つの特定のテーブル名のみを受け入れるため、ワイルドカードはサポートされていないことに注意してください。

    -   **ソース ファイルの URI と名前**: ソース ファイルの URI と名前を次の形式で入力します。 `s3://[bucket_name]/[data_source_folder]/[file_name].csv` .たとえば、 `s3://sampledate/ingest/TableName.01.csv` 。ワイルドカードを使用してソース ファイルと一致させることもできます。詳細については、 [マッピング設定](#mapping-settings)を参照してください。

6.  **[インポートの開始]**をクリックします。

7.  インポートの進行状況に**Completed**と表示されたら、インポートされたテーブルを確認します。

インポート タスクを実行するときに、サポートされていない変換または無効な変換が検出された場合、 TiDB Cloudはインポート ジョブを自動的に終了し、インポート エラーを報告します。

インポート エラーが発生した場合は、次の手順を実行します。

1.  部分的にインポートされたテーブルを削除します。
2.  テーブルスキーマファイルを確認してください。エラーがある場合は、テーブル スキーマ ファイルを修正します。
3.  CSVファイルのデータ型を確認してください。
4.  インポートタスクを再試行してください。

## マッピング設定 {#mapping-settings}

ソース ファイルが命名規則を満たしていない場合は、各ターゲット テーブルとそれに対応する CSV ファイルに対してカスタム マッピング ルールを定義できます。その後、提供されたカスタム マッピング ルールを使用してデータ ソース ファイルが再スキャンされます。マッピングを変更するには、 **「詳細設定」**に移動し、 **「マッピング設定」**をクリックします。 **[マッピング設定] は、** **[事前作成されたテーブルにインポート] を**選択した場合にのみ使用できることに注意してください。

[ソース ファイルの URI と名前] に**ソース ファイルの URI と**名前を入力する場合は、 `s3://[bucket_name]/[data_source_folder]/[file_name].csv`の形式であることを確認してください。たとえば、 `s3://sampledate/ingest/TableName.01.csv` 。

ワイルドカードを使用してソース ファイルと一致させることもできます。例えば：

-   `s3://[bucket_name]/[data_source_folder]/my-data?.csv` : そのフォルダー内の`my-data`で始まり、その後に 1 文字が続くすべての CSV ファイル ( `my-data1.csv`や`my-data2.csv`など) が同じターゲット テーブルにインポートされます。

-   `s3://[bucket_name]/[data_source_folder]/my-data*.csv` : `my-data`で始まるフォルダー内のすべての CSV ファイルが同じターゲット テーブルにインポートされます。

`?`と`*`のみがサポートされることに注意してください。

> **注記：**
>
> URI にはデータ ソース フォルダーが含まれている必要があります。

## トラブルシューティング {#troubleshooting}

### データインポート中の警告を解決する {#resolve-warnings-during-data-import}

**[インポートの開始]**をクリックした後、 `can't find the corresponding source files`などの警告メッセージが表示された場合は、正しいソース ファイルを提供するか、 [データインポートの命名規則](/tidb-cloud/naming-conventions-for-data-import.md)に従って既存のファイルの名前を変更するか、**詳細設定を**使用して変更することで問題を解決します。

これらの問題を解決した後、データを再度インポートする必要があります。

### インポートされたテーブルの行がゼロ {#zero-rows-in-the-imported-tables}

インポートの進行状況に**Completed**と表示されたら、インポートされたテーブルを確認します。行数がゼロの場合は、入力したバケット URI に一致するデータ ファイルがなかったことを意味します。この場合、正しいソース ファイルを提供するか、 [データインポートの命名規則](/tidb-cloud/naming-conventions-for-data-import.md)に従って既存のファイルの名前を変更するか、または**詳細設定**を使用して変更を加えることで、この問題を解決します。その後、それらのテーブルを再度インポートします。
