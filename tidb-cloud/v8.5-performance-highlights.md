---
title: TiDB Cloud Performance Highlights for TiDB v8.5.0
summary: Introduce the performance improvements for TiDB Cloud Dedicated clusters with the TiDB version of v8.5.0.
---

# TiDB Cloud Performance Highlights for TiDB v8.5.0

[TiDB v8.5.0](https://docs.pingcap.com/tidb/v8.5/release-8.5.0) is an important Long-Term Support (LTS) release, which delivers notable improvements in performance, scalability, and operational efficiency.

This document outlines the performance improvements in v8.5.0 across the following areas:

- General performance
- Hotspot reads with excessive MVCC versions
- IO latency jitter
- Batch processing
- TiKV scaling performance

## General performance

With the default Region size increased from 96 MiB to 256 MiB and some other improvements in v8.5, significant performance improvements were observed:

- `oltp_insert` performance improves by 27%
- `Analyze` performance shows a major boost of approximately 45%.

## Hotspot reads with excessive MVCC versions

### Challenge

In some user scenarios, the following challenges might occur:

- Frequent version updates: in some workloads, the data is updated and read very frequently.
- Long retention of historical versions: to meet business requirements, such as supporting flashback to specific time points, users might configure overly long GC (Garbage Collection) times (such as 24 hours). This results in an excessive accumulation of Multi-Version Concurrency Control (MVCC) versions, which significantly reduces query efficiency.

The accumulation of MVCC versions creates a large gap between the requested data and the processed data, leading to degraded read performance.

### Solution

To address this issue, TiKV introduces [In-Memory Engine (IME)](https://docs.pingcap.com/tidb/stable/tikv-in-memory-engine). By caching the latest versions in memory, TiKV reduces the impact of historical versions on read performance, significantly improving query efficiency.

### Test environment

- Cluster topology: TiDB (16 vCPU 32 GiB) \* 1 + TiKV (16 vCPU 32 GiB) \* 6
- Cluster configurations:

    ```toml
    tikv_configs:
    [in-memory-engine]
    enable = true
    ```

- Dataset: 24 GiB storage size with about 340 Regions, containing frequently updated data
- Workload: rows requiring scans contain numerous MVCC versions introduced by frequent updates

### Test results

The query latency decreases by 50%, and the throughput increases by 100%.

| Configurations | Duration | Threads | TPS | QPS | Average latency | P95 latency |
| --- |  --- |  --- |  --- |  --- |  --- |  --- |
| Disable IME | 3600s | 10 | 123.8 | 1498.3 | 80.76 | 207.82 |
| Enable IME | 3600s | 10 | 238.2 | 2881.5 | 41.99 | 78.60 |

## IO latency jitter

### Challenge

In cloud environments, transient or sustained IO latency fluctuations on cloud disks are a common challenge. These fluctuations can increase request latency, causing timeouts, errors, and disruptions to normal business operations, ultimately degrading service quality.

### Solution

TiDB v8.5 introduces multiple enhancements to address the impact of cloud disk IO jitter on performance. These improvements effectively mitigate the effects of IO latency fluctuations, ensuring more stable and reliable performance.

### Test environment

- Cluster topology: TiDB (32 vCPU 64 GiB) \* 3 + TiKV (32 vCPU 64 GiB) \* 6
- Workload: a read/write ratio of 2:1, with simulated cloud disk IO delays or hangs on one of TiKV nodes

### Test results

The failover time of the IO latency jitter is 30% shorter, and P99/999 latency is reduced by 70% or higher.

- Test results without IO latency jitter improvement

    | Workload | failover time | qps drop rate | max latency(P999/P99) |
    | --- |  --- |  --- |  --- |
    | IO delay 1s lasts for 10mins | 3mins | 93% | 4.66s/929ms |
    | IO delay 500ms lasts for 10mins | 2mins | 92% | 7.22s/894ms |
    | IO delay 100ms lasts for 10mins | 3mins | 80% | 7.53s/1.7s |
    | IO delay 50ms lasts for 10mins | 3mins | 53% | 1.36s/238ms |
    | IO delay 10ms lasts for 10mins | 3mins | 18% | 69ms/25ms |
    | IO delay 5ms lasts for 10mins | 2mins | 29% | 37.9ms/10ms |
    | IO delay 2ms lasts for 10mins | almost no effect | 1% | 14ms/7.9ms |

- Test results with IO latency jitter improvement

    | Workload | failover time | qps drop rate | max latency(P999/P99) |
    | --- |  --- |  --- |  --- |
    | IO delay 1s lasts for 10mins | 3mins | 93% | 4.66s/929ms |
    | IO delay 500ms lasts for 10mins | 2mins | 92% | 7.22s/894ms |
    | IO delay 100ms lasts for 10mins | 3mins | 80% | 7.53s/1.7s |
    | IO delay 50ms lasts for 10mins | 3mins | 53% | 1.36s/238ms |
    | IO delay 10ms lasts for 10mins | 3mins | 18% | 69ms/25ms |
    | IO delay 5ms lasts for 10mins | 2mins | 29% | 37.9ms/10ms |
    | IO delay 2ms lasts for 10mins | almost no effect | 1% | 14ms/7.9ms |

## Batch processing

### Challenge

Large-scale transactions, such as bulk data updates, system migrations, and ETL workflows, involve processing millions of rows and are vital for supporting critical operations. While TiDB excels as a distributed SQL database, handling such transactions at scale presents two significant challenges:

- Memory limits: in releases earlier than TiDB 8.1, all transaction mutations are held in memory throughout the transaction lifecycle, which strains resources and reduces performance. For operations involving millions of rows, this could lead to excessive memory usage and, in some cases, Out of Memory (OOM) errors when resources are insufficient.

- Performance slowdowns: managing large in-memory buffers relies on red-black trees, which introduces computational overhead. As buffers grew, their operations slowed down due to the *O(N log N)* complexity inherent in these data structures.

### Solution

These challenges highlighted a clear opportunity to improve scalability, reduce complexity, and enhance reliability. With the rise of modern data workloads, TiDB introduces the [Pipelined DML](https://docs.pingcap.com/tidb/stable/system-variables#tidb_dml_type-new-in-v800) feature, designed to change how large transactions are handled and improve resource utilization and overall performance.

### Test environment

- Cluster topology: TiDB (16 vCPU 32 GiB) \* 1 + TiKV (16 vCPU 32 GiB) \* 3
- Dataset: YCSB non-clustered table with 10 million rows (about 10GiB of data). Primary keys are selectively removed in certain tests to isolate and evaluate the impact of hotspot patterns.
- Workload: DML operations including `INSERT`, `UPDATE`, and `DELETE`.

### Test results

The execution speed increases by 2x, the maximum TiDB memory usage decreases by 50%, and the TiKV write flow becomes much smoother.

- Latency (second)

    | Workload (10 GiB) | standard DML | Pipelined DML | Improvement |
    | --- |  --- |  --- |  --- |
    | YCSB-insert-10M | 368 | 159 | 131.45% |
    | YCSB-update-10M | 255 | 131 | 94.66% |
    | YCSB-delete-10M | 136 | 42 | 223.81% |

- TiDB memory usage Peak (GiB)

    | Workload (10 GiB) | standard DML | Pipelined DML | Reduction |
    | --- |  --- |  --- |  --- |
    | YCSB-insert-10M | 25.8 | 12 | 53.49% |
    | YCSB-update-10M | 23.1 | 12.9 | 44.16% |
    | YCSB-delete-10M | 10.1 | 8.08 | 20.00% |

## TiKV scaling performance

### Challenge

Horizontal scaling is a core capability of TiKV, enabling the system to scale in or out as needed. As business demands grow and the number of tenants increases, TiDB clusters experience rapid growth in databases, tables, and data volume. Scaling out TiKV nodes quickly becomes essential to maintaining service quality.

In some scenarios, TiDB hosts a large number of databases and tables. When these tables are small or empty, TiKV accumulates a significant number of tiny regions, especially when the number of tables grows to a large scale (such as 1 million or more). These small regions introduce a substantial maintenance burden, increase resource overhead, and reduce efficiency.

### Solution

To address this issue, TiDB v8.5 improves the performance of merging small regions, reducing internal overhead and improving resource utilization. Additionally, TiDB v8.5 includes several other enhancements to further improve TiKV scaling performance.

### Test environment

#### Merging small regions

- Cluster topology: TiDB (16 vCPU 32 GiB) \* 1 + TiKV (16 vCPU 32 GiB) \* 3
- Dataset: nearly 1 million small tables, with the size of each table < 2 MiB
- Workload: Automatic merging of small Regions

#### Scaling out TiKV nodes

- Cluster topology: TiDB (16 vCPU 32 GiB) \* 1 + TiKV (16 vCPU 32 GiB) \* 4
- Dataset: TPC-C dataset with 20k warehouses
- Workload: scaling out TiKV nodes from 4 to 7

### Test results

The small Region merge speed improves by about 10 times.

| Metric | Without improvement | With improvement |
| --- |  --- |  --- |
| region merge duration (hrs) | 20 | 2 |

TiKV scaling performance improves by over 40%, and TiKV node scaling out duration gains a 30% reduction.

| Metric | Without improvement | With improvement |
| --- |  --- |  --- |
| TiKV scale out duration (hrs) | 5 | 3.5 |

## Benchmark

In addition to the preceding test data, you can refer to the following benchmark results for v8.5 performance:

- [TPC-C performance test report](/tidb-cloud/v8.5-performance-benchmarking-with-tpcc.md)
- [Sysbench performance test report](/tidb-cloud/v8.5-performance-benchmarking-with-sysbench.md)