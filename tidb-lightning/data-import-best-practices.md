---
title: Best Practices for Importing 50 TiB Data
summary: 大量のデータをインポートするためのベスト プラクティスを学びます。
---

# 50 TiB データのインポートに関するベストプラクティス {#best-practices-for-importing-50-tib-data}

このドキュメントでは、TiDBへの大容量データのインポートに関するベストプラクティスを解説します。データのインポートに影響を与える重要な要素や手順も含まれています。弊社では、50TiBを超える大規模な単一テーブルのデータを社内環境とお客様の環境の両方にインポートした実績があり、これらの実際のアプリケーションシナリオに基づいたベストプラクティスを蓄積してきました。これにより、よりスムーズかつ効率的にデータをインポートできるようになります。

TiDB Lightning （ [物理インポートモード](/tidb-lightning/tidb-lightning-physical-import-mode.md) ）は、空のテーブルにデータをインポートしたり、空のクラスターを初期化したりするために使用される包括的で効率的なデータインポートツールであり、ファイルをデータソースとして使用します。TiDB TiDB Lightningは、単一インスタンスと[並行輸入](/tidb-lightning/tidb-lightning-distributed-import.md) 2つの実行モードを提供します。さまざまなサイズのソースファイルをインポートできます。

-   ソース ファイルのデータ サイズが 10 TiB 以内の場合は、インポートにTiDB Lightningの単一インスタンスを使用することをお勧めします。
-   ソースファイルのデータサイズが 10 TiB を超える場合は、 [並行輸入](/tidb-lightning/tidb-lightning-distributed-import.md)に対してTiDB Lightningの複数のインスタンスを使用することをお勧めします。
-   ソース ファイルのデータ規模が非常に大きい場合 (50 TiB を超える場合)、並列インポートに加えて、ソース データの特性、テーブル定義、およびパラメータ構成に基づいて特定の準備と最適化を行い、大規模データのインポートをよりスムーズかつ高速に実現する必要があります。

次のセクションは、複数のテーブルのインポートと大きな単一のテーブルのインポートの両方に適用されます。

-   [主な要因](#key-factors)
-   [ソースファイルの準備](#prepare-source-files)
-   [storageスペースの見積もり](#estimate-storage-space)
-   [設定パラメータを変更する](#change-configuration-parameters)
-   [「チェックサム不一致」エラーを解決する](#resolve-the-checksum-mismatch-error)
-   [チェックポイントを有効にする](#enable-checkpoint)
-   [トラブルシューティング](#troubleshooting)

大きな単一テーブルをインポートするためのベスト プラクティスは、特別な要件があるため、次のセクションで別途説明します。

-   [大きな単一テーブルをインポートするためのベストプラクティス](#best-practices-for-importing-a-large-single-table)

## 主な要因 {#key-factors}

データをインポートする際、いくつかの重要な要素がインポートのパフォーマンスに影響を与え、場合によってはインポートが失敗する可能性があります。一般的な重要な要素には、次のようなものがあります。

-   ソースファイル

    -   単一ファイル内のデータが主キーでソートされているかどうか。ソートされたデータは最適なインポートパフォーマンスを実現します。
    -   複数のTiDB Lightningインスタンスによってインポートされたソースファイル間に、重複する主キーまたは非NULLの一意のインデックスが存在するかどうか。重複が少ないほど、インポートのパフォーマンスは向上します。

-   表の定義

    -   テーブルごとのセカンダリインデックスの数とサイズは、インポート速度に影響を与える可能性があります。インデックスの数が少ないほど、インポートが高速化し、インポート後のスペース消費も少なくなります。
    -   インデックス データ サイズ = インデックスの数 * インデックス サイズ * 行数。

-   圧縮比

    -   TiDBクラスタにインポートされたデータは圧縮形式で保存されます。圧縮率は事前に計算できません。圧縮率は、データが実際にTiKVクラスタにインポートされた後にのみ判定できます。
    -   ベスト プラクティスとして、最初にデータの小さな部分 (たとえば、10%) をインポートして、クラスターの対応する圧縮率を取得し、それを使用してデータ インポート全体の圧縮率を推定することができます。

-   コンフィグレーションパラメータ

    -   `region-concurrency` : TiDB Lightningのメイン論理処理の同時実行性。
    -   `send-kv-pairs` : 1 回のリクエストでTiDB Lightningから TiKV に送信されるキーと値のペアの数。
    -   `disk-quota` : 物理インポート モードを使用するときに、 TiDB Lightning のローカル一時ファイルによって使用されるディスク クォータ。
    -   `GOMEMLIMIT` : TiDB LightningはGo言語で実装されています[`GOMEMLIMIT`適切に設定します。](#change-configuration-parameters)

-   データ検証

    データとインデックスのインポートが完了すると、各テーブルに対して[`ADMIN CHECKSUM`](/sql-statements/sql-statement-admin-checksum-table.md)ステートメントが実行され、チェックサム値がTiDB Lightningのローカルチェックサム値と比較されます。テーブル数が多い場合、または個々のテーブルに多数の行がある場合、チェックサムフェーズに長い時間がかかることがあります。

-   分析操作

    チェックサムが正常に完了すると、各テーブルに対して[`ANALYZE TABLE`](/sql-statements/sql-statement-analyze-table.md)ステートメントが実行され、最適な実行プランが生成されます。多数のテーブル、または大量のデータを含む個々のテーブルを扱う場合、分析操作には時間がかかることがあります。

-   関連する問題

    50TiBのデータを実際にインポートするプロセスでは、膨大な数のソースファイルや大規模クラスタを扱う場合にのみ発生する特定の問題が発生する可能性があります。製品バージョンを選択する際には、該当する問題が修正されているかどうかを確認することをお勧めします。

    v6.5.3、v7.1.0 以降のバージョンでは、次の問題が解決されています。

    -   [問題-14745](https://github.com/tikv/tikv/issues/14745) : インポートが完了すると、TiKV インポート ディレクトリに大量の一時ファイルが残ります。
    -   [問題-6426](https://github.com/tikv/pd/issues/6426) : PD [レンジスケジュール](/tidb-lightning/tidb-lightning-physical-import-mode-usage.md#scope-of-pausing-scheduling-during-import)インターフェースがリージョンの分散に失敗し、タイムアウトの問題が発生する可能性があります。v6.2.0より前のバージョンでは、グローバルスケジューリングはデフォルトで無効になっているため、この問題の発生を回避できます。
    -   [問題-43079](https://github.com/pingcap/tidb/pull/43079) : TiDB Lightning は、NotLeader エラーの再試行中にリージョンピア情報を更新できません。
    -   [問題-43291](https://github.com/pingcap/tidb/issues/43291) : 一時ファイルが見つからない場合 (「そのようなファイルまたはディレクトリはありません」というエラー)、 TiDB Lightning は再試行しません。

## ソースファイルの準備 {#prepare-source-files}

-   ソースファイルを生成する際は、単一ファイル内で主キーでソートすることをお勧めします。テーブル定義に主キーがない場合は、自動増分主キーを追加できます。この場合、ファイルの内容の順序は関係ありません。
-   ソースファイルを複数のTiDB Lightningインスタンスに割り当てる際は、複数のソースファイル間で重複する主キーやnull以外の一意のインデックスが存在する状況を避けるようにしてください。生成されたファイルがグローバルにソートされている場合は、範囲に基づいて異なるTiDB Lightningインスタンスに分散することで、最適なインポートパフォーマンスを実現できます。
-   ファイル生成中に各ファイルのサイズが 96 MiB 未満になるように制御します。
-   ファイルが非常に大きく、256 MiB を超える場合は、 [`strict-format`](/migrate-from-csv-files-to-tidb.md#step-4-tune-the-import-performance-optional)有効にします。

## storageスペースの見積もり {#estimate-storage-space}

データのインポートに必要なstorage容量を見積もるには、次の 2 つの方法のいずれかを使用できます。

-   総データサイズを**A** 、総インデックスサイズを**B** 、レプリケーション係数を**3** 、圧縮率を**α** （通常は約2.5）と仮定すると、全体の占有領域は**(A+B)*3/α**で計算できます。この方法は主に、データのインポートを実行せずにクラスタトポロジを計画する際に、概算を行うために使用されます。
-   データの10%のみをインポートし、実際に使用されている容量に10を掛けることで、そのデータバッチの最終的な容量使用量を推定します。この方法は、特に大量のデータをインポートする場合に、より正確です。

圧縮やスナップショットのレプリケーションなどのバックグラウンド タスクもstorage領域の一部を消費するため、20% のstorage領域を予約することをお勧めします。

## 設定パラメータを変更する {#change-configuration-parameters}

-   `region-concurrency` : TiDB Lightning のメイン論理処理の同時実行性。並列インポート中は、リソースの過負荷と潜在的な OOM 問題を防ぐため、CPU コアの 75% に設定することをお勧めします。
-   `send-kv-pairs` : TiDB Lightningが1回のリクエストでTiKVに送信するキーと値のペアの数。この値は、send-kv-pairs * row-size &lt; 1 MiBという式に基づいて調整することをお勧めします。v7.2.0以降、このパラメータは`send-kv-size`に置き換えられ、追加の設定は不要です。
-   `disk-quota` : TiDB Lightningのソートディレクトリの容量がデータソースのサイズよりも大きいことを確認することをお勧めします。確保できない場合は、 `disk-quota` TiDB Lightningのソートディレクトリの容量の 80% に設定できます。これにより、 TiDB Lightning は指定された`disk-quota`に従ってデータを一括でソートして書き込みますが、この方法では完全なソート処理と比較してインポートパフォーマンスが低下する可能性があることに注意してください。
-   `GOMEMLIMIT` : TiDB LightningはGo言語で実装されています。インスタンスメモリの80%を`GOMEMLIMIT`に設定することで、GoのGCメカニズムによるOOMの発生確率を低減します。

TiDB Lightningパラメータの詳細については、 [TiDB Lightning構成パラメータ](/tidb-lightning/tidb-lightning-configuration.md)参照してください。

## 「チェックサム不一致」エラーを解決する {#resolve-the-checksum-mismatch-error}

データ検証中に競合が発生する可能性があります。エラーメッセージは「チェックサムが一致しません」です。この問題を解決するには、必要に応じて以下の手順を実行してください。

1.  ソースデータで、主キーまたは一意キーの競合がないか確認し、再インポート前に競合を解決してください。ほとんどの場合、これが最も一般的な原因です。
2.  テーブルの主キーまたは一意キーの定義が適切かどうかを確認してください。適切でない場合は、テーブル定義を修正してデータを再インポートしてください。
3.  上記の2つの手順を実行しても問題が解決しない場合は、ソースデータに少量（10%未満）の予期しない競合データが存在するかどうかを確認するために、さらに調査する必要があります。TiDB TiDB Lightningで競合データを検出して解決するには、 [競合検出](/tidb-lightning/tidb-lightning-physical-import-mode-usage.md#conflict-detection)有効にしてください。

## チェックポイントを有効にする {#enable-checkpoint}

大量データのインポートには、 [ライトニングチェックポイント](/tidb-lightning/tidb-lightning-checkpoints.md)を参照し、チェックポイントを有効にすることが必須です。コンテナ環境でTiDB Lightning を動作させている場合、コンテナが終了してチェックポイント情報が削除される可能性があるため、チェックポイント情報の消失を防ぐため、ドライバとして MySQL を優先的に使用することをお勧めします。

インポート中に下流のTiKVの容量が不足した場合は、すべてのTiDB Lightningインスタンスに対してコマンド`kill` （オプション`-9`なし）を手動で実行できます。容量をスケールアップした後、チェックポイント情報に基づいてインポートを再開できます。

## 大きな単一テーブルをインポートするためのベストプラクティス {#best-practices-for-importing-a-large-single-table}

複数のテーブルをインポートすると、チェックサムと分析の処理時間が長くなり、場合によってはデータのインポート自体にかかる時間を超えることがあります。ただし、通常は設定を調整する必要はありません。複数のテーブルの中に1つ以上の大きなテーブルがある場合は、それらの大きなテーブルのソースファイルを分割し、個別にインポートすることをお勧めします。

このセクションでは、大規模な単一テーブルをインポートするためのベストプラクティスを紹介します。大規模な単一テーブルには厳密な定義はありませんが、一般的には以下のいずれかの基準を満たすものと見なされます。

-   テーブルサイズが10 TiBを超えています。
-   幅の広い表では行数が 10 億を超え、列数が 50 を超えます。

### ソースファイルを生成する {#generate-source-files}

[ソースファイルの準備](#prepare-source-files)に記載されている手順に従います。

大きな単一テーブルの場合、グローバル ソートは実行できないが、主キーに基づいて各ファイル内でソートすることが可能であり、ファイルが標準の CSV ファイルである場合は、それぞれ約 20 GiB の大きな単一ファイルを生成することをお勧めします。

次に、 `strict-format`有効にします。このアプローチにより、 TiDB Lightningインスタンス間でインポートされたファイルの主キーと一意のキーの重複が削減され、 TiDB Lightningインスタンスはインポート前に大きなファイルを分割して、最適なインポート パフォーマンスを実現できます。

### クラスタトポロジを計画する {#plan-cluster-topology}

TiDB Lightningインスタンスを準備し、各インスタンスが5TiB～10TiBのソースデータを処理できるようにします。各ノードに1つのTiDB Lightningインスタンスをデプロイ。ノードの仕様については、 TiDB Lightningインスタンスの[環境要件](/tidb-lightning/tidb-lightning-physical-import-mode.md#environment-requirements)参照してください。

### 設定パラメータを変更する {#change-configuration-parameters}

-   TiDB Lightningインスタンスのコア数の`region-concurrency` ～ 75% を設定します。
-   `send-kv-pairs` `3200`に設定します。この方法はTiDB v7.1.0以前のバージョンに適用されます。v7.2.0以降では、このパラメータは`send-kv-size`に置き換えられ、追加の設定は不要です。
-   インスタンスが配置されているノード上のメモリを`GOMEMLIMIT` ～ 80% に調整します。

インポート プロセス中の PD 散布リージョンのレイテンシーが30 分を超える場合は、次の最適化を検討してください。

-   TiKV クラスターで I/O ボトルネックが発生しているかどうかを確認します。
-   TiKV `raftstore.apply-pool-size`デフォルト値の`2`から`4`または`8`に増やします。
-   TiDB Lightning `region-split-concurrency` CPU コア数の半分に減らします (最小値は`1` 。

### 分析操作を無効にする {#disable-the-analyze-operation}

単一のテーブルが大きい場合（たとえば、行数が 10 億行以上、列数が 50 列以上）、インポート処理中に`analyze`操作（ `analyze="off"` ）を無効にし、インポートが完了した後に[`ANALYZE TABLE`](/sql-statements//sql-statement-analyze-table.md)ステートメントを手動で実行することをお勧めします。

`analyze`の設定の詳細については、 [TiDB Lightningタスク構成](/tidb-lightning/tidb-lightning-configuration.md#tidb-lightning-task)参照してください。

## トラブルシューティング {#troubleshooting}

TiDB Lightningの使用中に問題が発生した場合は、 [TiDB Lightning のトラブルシューティング](/tidb-lightning/troubleshoot-tidb-lightning.md)参照してください。
